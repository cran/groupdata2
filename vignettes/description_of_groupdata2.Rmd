---
title: "Description of groupdata2"
author: 
  - "Ludvig Renbo Olsen"
date: "`r Sys.Date()`"
abstract: |
  groupdata2 is a set of subsetting methods for easy grouping, windowing, folding and splitting of data.
  Create balanced folds for cross-validation or divide a time series into windows.  
  This vignette contains descriptions of functions and methods, along with simple examples of usage. 
  For a more gentle introduction to groupdata2, please see [Introduction to groupdata2](introduction_to_groupdata2.html)
  &nbsp;  
  &nbsp;  
  Contact author at r-pkgs@ludvigolsen.dk
  &nbsp; 
  &nbsp;  
  
  -----
output: 
  rmarkdown::html_vignette:
    css: 
    - !expr system.file("rmarkdown/templates/html_vignette/resources/vignette.css", package = "rmarkdown")
    - styles.css
    fig_width: 6
    fig_height: 4
    toc: yes
    number_sections: no
  rmarkdown::pdf_document:
    highlight: tango
    number_sections: yes
    toc: yes
    toc_depth: 4
vignette: >
  %\VignetteIndexEntry{Description of groupdata2}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r include=FALSE}

knitr::opts_chunk$set(collapse = T, comment = "#>", fig.align='center')
options(tibble.print_min = 4L, tibble.print_max = 4L)

```


## Installing groupdata2  
You can either install the CRAN version or the GitHub development version.  

### CRAN version

```{r eval=FALSE}
# Uncomment:
# install.packages("groupdata2")  
```

### GitHub development version
```{r eval=FALSE}
# Uncomment:
# install.packages("devtools")  
# devtools::install_github("LudvigOlsen/groupdata2")
```

## Attach packages

```{r error=FALSE, message=FALSE, warning=FALSE}

# Attaching groupdata2
library(groupdata2)

# Attaching other packages used in this vignette
library(dplyr)
library(tidyr)
library(ggplot2)
library(knitr)

# We will also be using plyr a few times, but we don't attach this 
# because of possible conflicts with dplyr. Instead we use its functions
# like so: plyr::count()

```


# General information
groupdata2 is a set of functions and methods for easy grouping, windowing, folding and splitting of data.  

&nbsp;  

There are 4 main functions:  
&nbsp;  

### group_factor()  
Returns a factor with group numbers, e.g. 111222333.  
This can be used to subset, aggregate, group_by, etc.   

### group()  
Returns the given data as a dataframe with added grouping factor made with group_factor(). The dataframe is grouped by the grouping factor for easy use with dplyr pipelines.  

### splt()  
Splits the given data into the specified groups made with group_factor() and returns them in a list.  

### fold()  
Creates (optionally) balanced folds for use in cross-validation. Balance folds on one categorical variable and/or make sure that all datapoints sharing an ID is in the same fold.  

## Groups, windows or folds?  
When working with time series we would often refer to the kind of groups made by group_factor(), group() and splt() as **windows**. 
In this vignette, these will be referred to as groups.  

fold() creates balanced groups for cross-validation by using group(). These are referred to as **folds**.  

## Use of kable()

In the examples we will be using knitr::kable() to visualize some of the data such as dataframes. You do not need to use kable() in any way when using the functions.  

# Methods
There are currently 6 methods for grouping the data.  

It is possible to create groups based on group size, step size or number of groups. These can be given as whole number or percentage.   

Here we will take a look at the different methods. 

## Method: 'greedy'
'greedy' uses group **size** for dividing up the data.  
Greedy means that each group grabs as many elements as possible (up to size),
meaning that there might be less elements available to the last group, but 
that all other groups than the last are guaranteed to have the size specified.  

&nbsp;  
 
**Example**    

> We have a vector with 57 values. We want to have group sizes of 10.  
>  
> The greedy splitter will return groups with this many values in them:  
> 10, 10, 10, 10, 10, 7  

&nbsp;  

By setting **force_equal** to TRUE, we discard the last group if it contains fewer
values than the other groups.  

&nbsp;  
 
**Example**  

> We have a vector with 57 values. We want to have group sizes of 10.  
>  
> The greedy splitter with force_equal set to TRUE 
> will return groups with this many values in them:  
> 10, 10, 10, 10, 10  
>  
> meaning that 7 values have been discarded.  

&nbsp;  

## Method: 'n_dist' (Default)
'n_dist' uses a specified number of groups to divide up the data.  
First it creates equal groups as large as possible. Then, if there
are any excess data points, it distributes them across the groups.
 
&nbsp;  

**Example**    

> We have a vector with 57 values. We want to get back 5 groups.  
>   
> 'n_dist' with default settings would return groups with this many values in them:  
>   
> 11, 11, 12, 11, 12   
 
&nbsp;  

By setting **force_equal** to TRUE, 'n_dist' will create the largest possible, 
equally sized groups by discarding excess data elements.  

&nbsp;  

**Example**    

> 'n_dist' with **force_equal** set to TRUE would return groups with this many values in them:  
>   
> 11, 11, 11, 11, 11  
>  
> meaning that 2 values have been discarded.  

&nbsp;  

## Method: 'n_fill'
'n_fill' uses a specified number of groups to divide up the data.  
First it creates equal groups as large as possible. Then, if there
are any excess data points, it places them in the first groups.  
By setting **descending** to TRUE, it would be the last groups though.
 
&nbsp;  

**Example**    

> We have a vector with 57 values. We want to get back 5 groups.  
>   
> 'n_fill' with default settings would return groups with this many values in them:  
>   
> 12, 12, 11, 11, 11   
 
&nbsp;  

By setting **force_equal** to TRUE, 'n_fill' will create the largest possible, 
equally sized groups by discarding excess data elements.  

&nbsp;  

**Example**    

> 'n_fill' with **force_equal** set to TRUE would return groups with this many values in them:  
>   
> 11, 11, 11, 11, 11  
>  
> meaning that 2 values have been discarded.  

&nbsp;  


## Method: 'n_last'
'n_last' uses a specified number of groups to divide up the data.   

With *default settings*, it tries to make the groups as equally sized as possible,
but notice that the last group might contain fewer or more elements,
if the length of the data is not divisible with the number of groups. 
All, but the last, groups are guaranteed to contain the same number of elements.


&nbsp;  

**Example**    

> We have a vector with 57 values. We want to get back 5 groups.  
>   
> 'n_last' with default settings would return groups with this many values in them:  
>   
> 11, 11, 11, 11, 13   
 
&nbsp;  

By setting **force_equal** to TRUE, 'n_last' will create the largest possible, 
equally sized groups by discarding excess data elements.  

&nbsp;  

**Example**    

> 'n_last' with **force_equal** set to TRUE would return groups with this many values in them:  
>   
> 11, 11, 11, 11, 11  
>  
> meaning that 2 values have been discarded.  

&nbsp;  

Notice that 'n_last' will always return the given number of groups. It will never return a 
group with zero elements. For some situations that means that the last group will 
contain a lot of elements. Asked to divide a vector with 57 elements into 20 groups, 
the first 19 groups will contain 2 elements, while the last group will itself contain 19 elements. 
Had we instead asked it to divide the vector into 19 groups, we would have had 3 elements 
in all groups.

&nbsp;  

## Method: 'n_rand'
'n_fill' uses a specified number of groups to divide up the data.  
First it creates equal groups as large as possible. Then, if there
are any excess data points, it places them randomly in the groups.  
N.B.: It only places one extra element per group.
 
&nbsp;  

**Example**    

> We have a vector with 57 values. We want to get back 5 groups.  
>   
> 'n_rand' with default settings **could** return groups with this many values in them:  
>   
> 12, 11, 11, 11, 12   
 
&nbsp;  

By setting **force_equal** to TRUE, 'n_rand' will create the largest possible, 
equally sized groups by discarding excess data elements.  

&nbsp;  

**Example**    

> 'n_rand' with **force_equal** set to TRUE would return groups with this many values in them:  
>   
> 11, 11, 11, 11, 11  
>  
> meaning that 2 values have been discarded.  

&nbsp;  

## Method: 'staircase'  
'staircase' uses step_size to divide up the data.  
For each group, the group size will be step size multiplied with
the group index.  

&nbsp;  

**Example**    

> We have a vector with 57 values. We specify a step size of 5.  
>   
> 'staircase' with default settings would return groups with this many values in them:  
>   
> 5, 10, 15, 20, 7   
 
&nbsp;  

By setting **force_equal** to TRUE, 'staircase' will discard the last group if it does
not contain the expected values (step size multiplied by group index).  

&nbsp;  

**Example**    

> 'staircase' with **force_equal** set to TRUE would return groups with this many values in them:  
>   
> 5, 10, 15, 20   
>  
> meaning that 7 values have been discarded.  

&nbsp;  

### Find remainder - %staircase%
When using the staircase method the last group might not have the size of the second last group + step size.  
Use %staircase% to find the remainder.  

If the last group has the size of the second last group + step size, %staircase% will return 0.  

&nbsp;  

**Example**  

> %staircase% on a vector with size 57 and step size of 5 would look like this:
>
> 57 %staircase% 5
> 
> and return:
>
> 7
>
> meaning that the last group would contain 7 values 


# Arguments

## data

Type: dataframe or vector  

The data to process.  

&nbsp;

Used in: group_factor(), group(), splt(), fold()  
  

## n

Type: integer or numeric  

n represents either group size, step size or number of groups, depending on which method is specified.  
n can be given as a **whole number** (n > 1) or as **percentage** (0 < n < 1)  

&nbsp;

Used in: group_factor(), group(), splt()  

## method

Type: character  

Choose which method to use when dividing up the data.  
Available methods: greedy, n_dist, n_fill, n_last, n_rand, or staircase  

&nbsp;

Used in: group_factor(), group(), splt(), fold()  


## force_equal  

Type: logical (TRUE or FALSE)  

If you need groups with the exact same size, set force_equal to TRUE.  
Implementation is different in the different methods. Read more in their sections above.  
**Be aware** that this setting discards excess datapoints!  

&nbsp;

Used in: group_factor(), group(), splt()  

## allow_zero  

Type: logical (TRUE or FALSE)  

If you set n to 0, you get an error.  
If you don't want this behavior, you can set allow_zero to TRUE, and (depending on
the function) you will get the following output:  

*group_factor()* will return the factor with NAs instead of numbers. It will be
the same length as expected.  

*group()* will return the expected dataframe with NAs instead of a grouping factor.  

*splt()* functions will return the given data (dataframe or vector) in the same list format as if it had been split.  

&nbsp;

Used in: group_factor(), group(), splt()  


## descending

Type: logical (TRUE or FALSE)  

In methods like 'n_fill' where it makes sense to change the direction of the method, you can use this argument.  
In 'n_fill' it fills up the excess data points starting from the last group instead of the first.  
NB. Only some of the methods can use this argument.  

&nbsp;

Used in: group_factor(), group(), splt()  

## randomize

Type: logical (TRUE or FALSE)  

After creating the the grouping factor using the chosen method, it is possible to randomly reorganize it before returning it. Notice that this **applies to all the functions**, as group() and splt() uses the grouping factor!  

&nbsp;

Used in: group_factor(), group(), splt()  

N.B. fold() always uses some randomization.  

## col_name

Type: character  

Name of added grouping factor column. Allows multiple grouping factors in a dataframe.  

&nbsp;  

Used in: group()  

## k

Type: integer or numeric  

k represents either fold size, step size or number of folds, depending on which method is specified.  
k can be given as a **whole number** (n > 1) or as **percentage** (0 < n < 1)  

&nbsp;

Used in: fold()  

## cat_col

Type: categorical vector or factor (passed as column name)  

Categorical variable to balance between folds.  

E.g. when predicting a binary variable (a or b), it is necessary to have both represented in every fold.  

&nbsp;

**N.B.** If also passing id_col, cat_col should be a constant within IDs.  
E.g. a participant must always have the same diagnosis (a or b) throughout the dataset. 
Else, the participant might be placed in multiple folds.  

&nbsp;

Used in: fold()  

## id_col

Type: Factor (passed as column name)  

Factor with IDs. This will be used to keep all rows with an ID in the same fold (if possible).  

E.g. If we have measured a participant multiple times and want to see the effect of time, we want to have all observations of this participant in the same fold.  

&nbsp;

Used in: fold()  

&nbsp;


# Using Functions

We will be using 'n_dist' on a dataframe to showcase the functions. Afterwards we will use and compare the methods.  
Notice that you can also use vectors with all the functions.  

## group_factor()  

1. We create a dataframe  

```{r}
df <- data.frame("x"=c(1:12), 
                "species" = rep(c('cat','pig', 'human'), 4), 
                "age" = sample(c(1:100), 12))

```

2. Using group_factor()  

```{r}
groups <- group_factor(df, 5, method = 'n_dist')

groups

df$groups <- groups

df %>% kable(align = 'c')

```

3. We could get the mean age of each group  

```{r}
aggregate(df[, 3], list(df$groups), mean) %>% 
  rename(group = Group.1, mean_age = x) %>%
  kable(align = 'c')

```

### force_equal

Getting an equal number of elements per group with group_factor().  

Notice that we discard the excess values so all groups contain the same amount of elements.
Since the grouping factor is shorter than the dataframe, we can't combine them as they are. A way to do so would be to shorten the dataframe to be the same length as the grouping factor. 

1. We create a dataframe  

```{r}
df <- data.frame("x"=c(1:12), 
                "species" = rep(c('cat','pig', 'human'), 4), 
                "age" = sample(c(1:100), 12))

```

2. Using group_factor() with force_equal   

```{r}
groups <- group_factor(df, 5, method = 'n_dist', force_equal = TRUE)

groups

plyr::count(groups) %>% 
  rename(group = x, size = freq) %>%
  kable(align = 'c')

```

3. Combining dataframe and grouping factor  

First we make the dataframe the same size as the grouping factor. Then we add the grouping factor to the dataframe.  

```{r}
df <- head(df, length(groups)) %>%
  mutate(group = groups)

df %>% kable(align = 'c')

```

&nbsp;  
 
 
## group()  

1. We create a dataframe  

```{r}
df <- data.frame("x"=c(1:12), 
                "species" = rep(c('cat','pig', 'human'), 4), 
                "age" = sample(c(1:100), 12))

```

2. Using group()  

```{r}
df_grouped <- group(df, 5, method = 'n_dist')

df_grouped %>% kable(align = 'c')

```

2.2 Using group() with dplyr pipelines to get mean age

```{r}
df_means <- df %>%
  group(5, method = 'n_dist') %>%
  dplyr::summarise(mean_age = mean(age))

df_means %>% kable(align = 'c')

```



### force_equal

Getting an equal number of elements per group with group().  

Notice that we discard the excess rows/elements so all groups contain the same amount of elements.


1. We create a dataframe  

```{r}
df <- data.frame("x"=c(1:12), 
                "species" = rep(c('cat','pig', 'human'), 4), 
                "age" = sample(c(1:100), 12))


```

2. Using group() with force_equal   

```{r}
df_grouped <- df %>%
  group(5, method = 'n_dist', force_equal = TRUE)

df_grouped %>% kable(align = 'c')

```


&nbsp;  
 

## splt()  

1. We create a dataframe  

```{r}
df <- data.frame("x"=c(1:12), 
                "species" = rep(c('cat','pig', 'human'), 4), 
                "age" = sample(c(1:100), 12))


```

2. Using splt()  

```{r}
df_list <- splt(df, 5, method = 'n_dist')

df_list %>% kable(align = 'c')

```

3. Let's see the format of the list created by splt() without using kable() to visualize it.  
splt() uses base::split() to split the data by the grouping factor.

```{r}

v = c(1:6)

splt(v, 3, method = 'n_dist')

```


### force_equal

Getting an equal number of elements per group with splt().  

Notice that we discard the excess rows/elements so all groups contain the same amount of elements.


1. We create a dataframe  

```{r}
df <- data.frame("x"=c(1:12), 
                "species" = rep(c('cat','pig', 'human'), 4), 
                "age" = sample(c(1:100), 12))

```

2. Using splt() with force_equal   

```{r}
df_list <- splt(df, 5, method = 'n_dist', force_equal = TRUE)

df_list %>% kable(align = 'c')

```


&nbsp;  
 
## fold()  

1. We create a dataframe  

```{r}
df <- data.frame("participant" = factor(rep(c('1','2', '3', '4', '5', '6'), 3)),
                "age" = rep(sample(c(1:100), 6), 3),
                "diagnosis" = rep(c('a', 'b', 'a', 'a', 'b', 'b'), 3),
                "score" = sample(c(1:100), 3*6))

df <- df[order(df$participant),] 

# Remove index
rownames(df) <- NULL

# Add session info
df$session <- rep(c('1','2', '3'), 6)

kable(df, align = 'c')

```

2. Using fold() without balancing  

```{r}
df_folded <- fold(df, 3, method = 'n_dist')

# Order by folds
df_folded <- df_folded[order(df_folded$.folds),]

kable(df_folded, align = 'c')


```

3. Using fold() with balancing but without id_col  

```{r}
df_folded <- fold(df, 3, cat_col = 'diagnosis', method = 'n_dist')

# Order by folds
df_folded <- df_folded[order(df_folded$.folds),] 

kable(df_folded, align = 'c')

```

Let's count how many of each diagnosis there are in each group.  

```{r}
df_folded %>% group_by(.folds) %>% count(diagnosis) %>% kable(align='c')

```

4. Using fold() with id_col but without balancing  

```{r}
df_folded <- fold(df, 3, id_col = 'participant', method = 'n_dist')

# Order by folds
df_folded <- df_folded[order(df_folded$.folds),] 

# Remove index (Looks prettier in the table!)
rownames(df_folded) <- NULL

kable(df_folded, align = 'c')

```

Let's see how participants were distributed in the groups.  

```{r}
df_folded %>% group_by(.folds) %>% count(participant) %>% kable(align='c')

```

5. Using fold() with balancing and with id_col  

fold() first divides up the dataframe by cat_col and then create n folds for both diagnoses. As there are only 3 participants per diagnosis, we can maximally create 3 folds in this scenario.  

```{r}
df_folded <- fold(df, 3, cat_col = 'diagnosis', id_col = 'participant', method = 'n_dist')

# Order by folds
df_folded <- df_folded[order(df_folded$.folds),] 

kable(df_folded, align = 'c')

```

Let's count how many of each diagnosis there are in each group and find which participants are in which groups.

```{r}
df_folded %>% group_by(.folds) %>% count(diagnosis, participant) %>% kable(align='c')

```


&nbsp;  
 
## Extra arguments showcase

### randomize

1. We create a dataframe  

```{r}
df <- data.frame("x"=c(1:12), 
                "species" = rep(c('cat','pig', 'human'), 4), 
                "age" = sample(c(1:100), 12))

```

2. We use group_factor() with randomize set to TRUE

```{r}
groups <- group_factor(df, 5, method = 'n_dist', randomize = TRUE)

groups

```

3. We use splt() with randomize set to TRUE  
Notice that the index has been shuffled but the group sizes are the same as before!
 
```{r}
df_list <- splt(df, 5, method = 'n_dist', randomize = TRUE)

df_list %>% kable(align = 'c')

```
 
 
# Examples of method differences

In this section we will take a look at the outputs we get from the different methods.


## n_ methods


### Vector with 57 elements divided into 6 groups

Below you'll see a dataframe with counts of group elements when dividing up the same data with the different n_ methods. 
The forced_equal column is simply with the force_equal set to TRUE.   

forced_equal: Since this is a setting to make sure that all groups are of the same size, 
it makes sense that all the groups have the same size.  

n_dist: compared to forced_equal we see the 3 datapoints that forced_equal had discarded. These are distributed across the groups (in this example group 2,4 and 6)  

n_fill: The 3 extra datapoints are located at the first 3 groups. Had we set descending to TRUE, 
it would have been the last 3 groups instead.   

n_last: We see that n_last creates equal group sizes in all but the last group. This means that the last group can sometimes have a group size, which is very large or small compared to the other groups. Here it is a third larger than the other groups.  

n_rand: The extra datapoints are placed randomly and so we would see the extra datapoints located at different groups if we ran the script again. *Unless we use set.seed() before running the function.*  


```{r echo=FALSE}

# 
# Examples to show difference between methods
# This could be made interactive! This way you could test what happens in different situations by 
# by simply moving a slider!
#

vec <- c(1:57)

n <- 6

if (exists ('n_meth_v57n6')){
  rm(n_meth_v57n6)
  }

for (meth in c('n_dist', 'n_fill' ,'n_last','n_rand')){
  
  data_temp <- data.frame(plyr::count(group_factor(vec, n, method = meth)))
  
  names(data_temp)[names(data_temp)=="freq"] <- meth
  
  if (exists ('n_meth_v57n6')) {
    
    n_meth_v57n6 <- cbind(n_meth_v57n6, data_temp)
    
  } else {
    
    n_meth_v57n6 <- data_temp
    
  }
  
}

forced_equal <- plyr::count(group_factor(vec, n, method = 'n_last', force_equal = TRUE))

n_meth_v57n6$forced_equal <- forced_equal$freq

n_meth_v57n6 <- n_meth_v57n6[ , !duplicated(colnames(n_meth_v57n6))]


# gather() dataframe for plotting

data_plot <- n_meth_v57n6 %>%
  gather(method, group_size,-1)


upper_limit <- max(data_plot$group_size)+1
lower_limit <- min(data_plot$group_size)-1


v57n6_plot <- ggplot(data_plot, aes(x, group_size))


## Output

# Dataframe
n_meth_v57n6

# Plot
v57n6_plot +
  geom_point() +
  scale_y_continuous(limit = c(lower_limit, upper_limit),
                     breaks = round(seq(lower_limit, upper_limit, by = 2),1)) + 
  #scale_y_continuous(limit = c(lower_limit, upper_limit))+
  facet_wrap('method', ncol=1) +
  labs(x = 'group',
       y = 'group Size',
       title = 'Distribution of Elements in groups')+
  theme_bw()+
  theme(axis.text.y = element_text(size=9),
        axis.text.x = element_text(size=9))
        




```

&nbsp; 

### Vector with 117 elements divided into 11 groups

Here is another example.   

```{r echo=FALSE}



vec <- c(1:117)

n <- 11

if (exists ('n_meth_v117n11')){
  rm(n_meth_v117n11)
  }

for (meth in c('n_dist', 'n_fill' ,'n_last','n_rand')){
  
  data_temp <- data.frame(plyr::count(group_factor(vec, n, method = meth)))
  
  names(data_temp)[names(data_temp)=="freq"] <- meth
  
  if (exists ('n_meth_v117n11')) {
    
    n_meth_v117n11 <- cbind(n_meth_v117n11, data_temp)
    
  } else {
    
    n_meth_v117n11 <- data_temp
    
  }
  
}

forced_equal <- plyr::count(group_factor(vec, n, method = 'n_last', force_equal = TRUE))

n_meth_v117n11$forced_equal <- forced_equal$freq

n_meth_v117n11 <- n_meth_v117n11[ , !duplicated(colnames(n_meth_v117n11))]




# gather() dataframe for plotting

data_plot <- n_meth_v117n11 %>%
  gather(method, group_size,-1)

v117n11_plot <- ggplot(data_plot, aes(x, group_size))


upper_limit <- max(data_plot$group_size)+1
lower_limit <- min(data_plot$group_size)-1


## Output

# Dataframe
n_meth_v117n11

# Plot
v117n11_plot + 
  geom_point() + 
  scale_y_continuous(limit = c(lower_limit, upper_limit),
                     breaks = round(seq(lower_limit, upper_limit, by = 2),1)) + 
  facet_wrap('method', ncol=1) + 
  labs(x = 'group',
       y = 'group Size',
       title = 'Distribution of Elements in groups')+
  theme_bw()+
  theme(axis.text.y = element_text(size=9),
        axis.text.x = element_text(size=9))


  

```

&nbsp; 



## Greedy

### Vector with 100 elements with sizes of 8, 15, 20

Below you will see group sizes when using the method 'greedy' and asking for group sizes of 8, 15, 20. What should become clear is that only the last group can have a different group size than what we asked for. This is important if, say, you want to split a time series into groups of 100 elements, but the time series is not divisible with 100. Then you could use force_equal to remove the excess elements, if you need equal groups.

With a size of 8, we get 13 groups. The last group (13) only contains 4 elements, but all the other groups contain 8 elements as specified.

With a size of 15, we get 7 groups. The last group (7) contains only 10 elements, but all the other groups contain 15 elements as specified.

With a size of 20, we get 5 groups. As 20 is divisible with the 100 elements that the splitted vector contained, the last group also contains 20 elements, and so we have equal groups.

```{r echo=FALSE}


vec <- c(1:100)

if (exists ('greedy_data')){
  rm(greedy_data)
  }

for (n in c(8,15,20)){

  group_sizes <- plyr::count(group_factor(vec, n, method='greedy'))

  data_temp <- data.frame(group_sizes, 'Size' = factor(n))

  
  if (exists ('greedy_data')) {
    
    greedy_data <- rbind(greedy_data, data_temp)
    
  } else {
    
    greedy_data <- data_temp
    
  }
  
}


greedy_plot <- ggplot(greedy_data, aes(x, freq, color=Size))

greedy_plot + 
  geom_point() +
  labs(x = 'group',
       y = 'group Size',
       title = 'Greedy Distribution of Elements in groups',
       color = 'Size') +
  theme_bw()+
  theme(plot.margin = unit(c(1,1,1,1), "cm"))+
  theme(axis.text.y = element_text(size=9),
        axis.text.x = element_text(size=9))


```


&nbsp; 


## Staircasing

### Vector with 1000 elements with step sizes of 2, 5, 11

Below you'll see a plot with the group sizes at each group when using step sizes 2, 5, and 11.

At a step size of 2 elements it simply increases 2 for each group, until the last group (32) where it runs out of elements. Had we set force_equal to TRUE, this last group would have been discarded, because of the lack of elements.

At a step size of 5 elements it increases with 5 every time. Because of this it runs out of elements faster. Again we see that the last group (20) has fewer elements.

At a step size of 11 elements it increases with 11 every time. It seems that the last group is not too small, but it can be hard to see on this scale. Actually, the last group misses 1 element to be complete and so would have been discarded if force_equal was set to TRUE.  

&nbsp; 


```{r echo=FALSE}


vec <- c(1:1000)

if (exists ('staircase_data')){
  rm(staircase_data)
  }

for (n in c(2, 5, 11)){

  group_sizes <- plyr::count(group_factor(vec, n, method='staircase'))

  data_temp <- data.frame(group_sizes, 'step_size' = factor(n))

  
  if (exists ('staircase_data')) {
    
    staircase_data <- rbind(staircase_data, data_temp)
    
  } else {
    
    staircase_data <- data_temp
    
  }
  
}

staircase_plot <- ggplot(staircase_data, aes(x, freq, color=step_size))

staircase_plot + 
  geom_point() +
  #scale_x_continuous(breaks = round(seq(1, max(data_temp$x), by = 2),1))+
  labs(x = 'group',
       y = 'group Size',
       title = 'Staircasing Distribution of Elements in groups',
       color = 'Step Size') +
  theme_bw()+
  theme(axis.text.y = element_text(size=9),
        axis.text.x = element_text(size=7))



```


&nbsp; 


Below we will take a quick look at the cumulative sum of group elements to get an idea of what is going on under the hood.  
Remember that the splitted vector had 1000 elements? That is why they all stop at 1000 on the y-axis. There are simply no more elements left!  


```{r echo=FALSE}

staircase_data <- staircase_data %>%
  group_by(step_size) %>%
  mutate(cumsum = cumsum(freq))

staircase_cumulative_plot <- ggplot(staircase_data, aes(x, cumsum, color=step_size))

staircase_cumulative_plot + 
  geom_point() +
  labs(x = 'group',
       y = 'Cumulative sum of group sizes',
       title = 'Staircasing Cumulative Sum of group Sizes',
       color = 'Step Size') +
  theme_bw()+
  theme(axis.text.y = element_text(size=9),
        axis.text.x = element_text(size=7))

```

# The End
You have reached the end! Now celebrate by taking the week off, splitting data and laughing!  



